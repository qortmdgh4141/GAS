{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 🚀 GAS Demo (ICML 2025)\n",
        "Paper: https://arxiv.org/abs/2506.07744  \n",
        "GitHub: https://github.com/qortmdgh4141/GAS  \n",
        "Project page: https://qortmdgh4141.github.io/projects/GAS  \n",
        "Talk (10min): https://www.youtube.com/watch?v=6mxRlbn2_6s\n",
        "\n",
        "This notebook demonstrates how to run pretrained GAS checkpoints and visualize trajectories."
      ],
      "metadata": {
        "id": "AJ1YC3rTBbmz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. **Setup**"
      ],
      "metadata": {
        "id": "dTTSaVBoBhiy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone -q https://github.com/qortmdgh4141/GAS.git\n",
        "%cd /content/GAS\n",
        "\n",
        "!pip -q install ogbench==1.1.5\n",
        "!pip -q install distrax==0.1.5\n",
        "!pip -q install ml_collections==0.1.1"
      ],
      "metadata": {
        "id": "u9D-ABQWo9U6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "os.environ['MUJOCO_GL'] = 'egl'\n",
        "\n",
        "import jax\n",
        "import random\n",
        "import mujoco\n",
        "import ogbench\n",
        "import imageio\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from IPython.display import Video, display\n",
        "from huggingface_hub import snapshot_download\n",
        "\n",
        "from K_utils.keygraph_utils import KeyGraph\n",
        "from M_utils.agents import gas, agents_dict\n",
        "from M_utils.flax_utils import restore_agent"
      ],
      "metadata": {
        "id": "hGywXjs4u3uE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. **Define helper functions**"
      ],
      "metadata": {
        "id": "Pjzrw5x2C1XD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def supply_rng(f, rng=jax.random.PRNGKey(0)):\n",
        "    \"\"\"Helper function to split the random number generator key before each call to the function.\"\"\"\n",
        "    def wrapped(*args, **kwargs):\n",
        "        nonlocal rng\n",
        "        rng, key = jax.random.split(rng)\n",
        "        return f(*args, seed=key, **kwargs)\n",
        "    return wrapped\n",
        "\n",
        "def demo_evaluate_with_graph(agent, key_graph, env, shadow_renderer, top_cam, ego_cam, front_cam, env_name, task_id, seed, eval_on_cpu, eval_subgoal_threshold, eval_final_goal_threshold,):\n",
        "    \"\"\"\n",
        "    Evaluate the GAS in the environment.\n",
        "    In OGbench environments, the final goal includes slight random noise per episode.\n",
        "    Empirically, we found little to no performance difference between:\n",
        "    (1) Recomputing the shortest path every episode\n",
        "    (2) Reusing a precomputed path for the same task_id\n",
        "\n",
        "    The function `demo_evaluate_with_graph()` follows (2) by computing the shortest path once via `precompute_shortest_paths_to_all_tasks()`\n",
        "    When using (2), we recommend setting `eval_final_goal_threshold >= 2` to allow agents to reach slightly perturbed final goals.\n",
        "    If final goals vary significantly per episode, or if GAS is extended to online RL, strategy (1) is preferred.\n",
        "    \"\"\"\n",
        "    eval_agent = jax.device_put(agent, device=jax.devices('cpu')[0]) if eval_on_cpu else agent\n",
        "    get_phi_fn = eval_agent.get_phi\n",
        "    actor_fn = supply_rng(eval_agent.sample_actions, rng=jax.random.PRNGKey(seed))\n",
        "\n",
        "    steps = 0\n",
        "    infos = []\n",
        "    frames = []\n",
        "    observation, info = env.reset(seed=seed, options=dict(task_id=task_id, render_goal=True))\n",
        "    goal = info.get('goal')\n",
        "    done = False\n",
        "\n",
        "    epsilon=1e-10\n",
        "    phi_obs = np.array(get_phi_fn(observation))\n",
        "    phi_goal = np.array(get_phi_fn(goal))\n",
        "    final_goal_on = False\n",
        "    shortest_path = key_graph.get_shortest_path(task_id=task_id, source=phi_obs, force_closest=True)\n",
        "    while not done:\n",
        "        phi_obs = np.array(get_phi_fn(observation))\n",
        "        if final_goal_on:\n",
        "            cur_obs_goal = phi_goal\n",
        "        else:\n",
        "            cached_shortest_path = key_graph.get_shortest_path(task_id=task_id, source=phi_obs)\n",
        "            if cached_shortest_path is None:\n",
        "                pass\n",
        "            else:\n",
        "                shortest_path = cached_shortest_path\n",
        "\n",
        "            distances = np.linalg.norm(np.array(shortest_path) - phi_obs, axis=1)\n",
        "            valid_indices = np.where(distances <= eval_subgoal_threshold)[0]\n",
        "            cur_node_idx = valid_indices[-1] if len(valid_indices) > 0 else 0\n",
        "            if len(shortest_path) <= eval_final_goal_threshold:\n",
        "                final_goal_on = True\n",
        "                cur_obs_goal = phi_goal\n",
        "            else:\n",
        "                cur_obs_goal = shortest_path[cur_node_idx]\n",
        "\n",
        "        skills = (cur_obs_goal - phi_obs) / (np.linalg.norm(cur_obs_goal - phi_obs) + epsilon)\n",
        "        action = actor_fn(observations=observation, goals=skills, temperature=0.0)\n",
        "        action = np.clip(np.array(action), -1, 1)\n",
        "\n",
        "        next_observation, reward, terminated, truncated, info = env.step(action)\n",
        "        done = terminated or truncated\n",
        "        steps += 1\n",
        "        if steps % 3 == 0 or done:\n",
        "            infos.append(info)\n",
        "            if \"antmaze\" in env_name:\n",
        "                assert top_cam is not None and ego_cam is not None, \"Antmaze cameras not initialized.\"\n",
        "                shadow_renderer.update_scene(env.unwrapped.data, camera=top_cam)\n",
        "                top_frame = shadow_renderer.render()\n",
        "                ego_cam.lookat[0] = float(info[\"xy\"][0])\n",
        "                ego_cam.lookat[1] = float(info[\"xy\"][1])\n",
        "                shadow_renderer.update_scene(env.unwrapped.data, camera=ego_cam)\n",
        "                ego_frame = shadow_renderer.render()\n",
        "                frame = np.concatenate([top_frame, ego_frame], axis=1)\n",
        "            elif \"scene\" in ENV_NAME:\n",
        "                assert front_cam is not None, \"Scene front camera not initialized.\"\n",
        "                shadow_renderer.update_scene(env.unwrapped.data, camera=front_cam)\n",
        "                frame = shadow_renderer.render()\n",
        "            else:\n",
        "                raise RuntimeError(f\"Unsupported environment: {ENV_NAME}\")\n",
        "            frames.append(frame)\n",
        "        observation = next_observation\n",
        "\n",
        "    return frames, infos, steps"
      ],
      "metadata": {
        "id": "vBkkmgggRLn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Configure environment & agent"
      ],
      "metadata": {
        "id": "4AzaV0J1Btlh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the environment.\n",
        "ENV_NAME_LIST = [\"antmaze-giant-navigate-v0\", \"antmaze-giant-stitch-v0\", \"antmaze-large-explore-v0\", \"scene-play-v0\",\n",
        "                 \"visual-antmaze-giant-navigate-v0\", \"visual-antmaze-giant-stitch-v0\", \"visual-antmaze-large-explore-v0\", \"visual-scene-play-v0\",]\n",
        "ENV_NAME = ENV_NAME_LIST[4] # Change the index to select the desired environment 🌍\n",
        "\n",
        "# Select the task ID.\n",
        "TASK_ID_LIST = [1, 2, 3, 4, 5]\n",
        "TASK_ID = TASK_ID_LIST[0] # Change the index to select the desired task 🎯"
      ],
      "metadata": {
        "id": "Pf6AG8cBQ23l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seeds and configuration (usually no need to change)\n",
        "seed = 0\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "eval_final_goal_threshold = 2\n",
        "config = gas.get_config()\n",
        "\n",
        "if ENV_NAME.startswith(\"visual-\"):\n",
        "    eval_on_cpu = 0\n",
        "    config[\"encoder\"] = \"impala_small\"\n",
        "else:\n",
        "    eval_on_cpu = 1\n",
        "    config[\"encoder\"] = \"not_used\"\n",
        "\n",
        "if ENV_NAME.startswith(\"scene-play\"):\n",
        "    config[\"way_steps\"] = 48\n",
        "elif ENV_NAME.startswith(\"visual-scene-play\"):\n",
        "    config[\"way_steps\"] = 24\n",
        "else:\n",
        "    config[\"way_steps\"] = 8\n",
        "\n",
        "# Set up environment.\n",
        "env = ogbench.make_env_and_datasets(ENV_NAME, env_only=True)\n",
        "env.unwrapped.model.vis.global_.offwidth  = 400\n",
        "env.unwrapped.model.vis.global_.offheight = 400\n",
        "shadow_renderer = mujoco.Renderer(env.unwrapped.model, width=400, height=400)\n",
        "\n",
        "top_cam = None\n",
        "ego_cam = None\n",
        "front_cam = None\n",
        "if \"antmaze\" in ENV_NAME:\n",
        "    top_cam = mujoco.MjvCamera()\n",
        "    top_cam_params_list = [(\"giant\", (26, 18, 70, -90)), (\"large\", (18, 12, 50, -90)),]\n",
        "    for key, (lx, ly, dist, elev) in top_cam_params_list:\n",
        "        if key in ENV_NAME:\n",
        "            (top_cam.lookat[0], top_cam.lookat[1], top_cam.distance, top_cam.elevation) = (lx, ly, dist, elev)\n",
        "            break\n",
        "    ego_cam = mujoco.MjvCamera()\n",
        "    (ego_cam.distance, ego_cam.elevation) = (10, -50)\n",
        "elif \"scene\" in ENV_NAME:\n",
        "    cam_name = \"front\" #\"front_pixels\" if ENV_NAME.startswith(\"visual-\") else \"front\"\n",
        "    cam_id = mujoco.mj_name2id(env.unwrapped.model, mujoco.mjtObj.mjOBJ_CAMERA, cam_name)\n",
        "    front_cam = mujoco.MjvCamera()\n",
        "    mujoco.mjv_defaultCamera(front_cam)\n",
        "    front_cam.type = mujoco.mjtCamera.mjCAMERA_FIXED\n",
        "    front_cam.fixedcamid = cam_id\n",
        "else:\n",
        "    raise RuntimeError(f\"Unsupported environment: {ENV_NAME}\")"
      ],
      "metadata": {
        "id": "6e8DeBohqKRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize agent.\n",
        "obs_space = env.observation_space\n",
        "act_space = env.action_space\n",
        "if len(obs_space.shape) == 3:\n",
        "    ex_obs = np.random.randint(0, 256, size=(1, *obs_space.shape), dtype=np.uint8)\n",
        "else:\n",
        "    ex_obs = np.random.randn(1, obs_space.shape[0]).astype(np.float32)\n",
        "ex_act = np.random.randn(1, act_space.shape[0]).astype(np.float32)\n",
        "\n",
        "agent_class = agents_dict[config['agent_name']]\n",
        "agent = agent_class.create(seed, ex_obs, ex_act, config,)\n",
        "\n",
        "# Download official GAS checkpoints.\n",
        "ckpt_dir = \"checkpoints\"\n",
        "os.makedirs(ckpt_dir, exist_ok=True)\n",
        "env_folder = ENV_NAME.replace(\"-v0\", \"\")\n",
        "snapshot_download(repo_id=\"qortmdgh4141/GAS\", local_dir=ckpt_dir, allow_patterns=[f\"{env_folder}/*\"],)\n",
        "\n",
        "# Restore graph.\n",
        "key_graph = KeyGraph()\n",
        "keygraph_path = os.path.join(ckpt_dir, env_folder, \"keygraph.pkl\")\n",
        "keygraph_load_path = os.path.dirname(keygraph_path)\n",
        "keygraph_load_filename = os.path.basename(keygraph_path).split('_')[-1].split('.')[0]\n",
        "key_graph.load_keygraph(keygraph_load_path, keygraph_load_filename)\n",
        "\n",
        "# Restore low-level policy.\n",
        "params_file = \"params_500000.pkl\" if ENV_NAME.startswith(\"visual-\") else \"params_1000000.pkl\"\n",
        "policy_path = os.path.join(ckpt_dir, env_folder, params_file)\n",
        "policy_restore_path = os.path.dirname(policy_path)\n",
        "policy_restore_epoch = os.path.basename(policy_path).split('_')[-1].split('.')[0]\n",
        "agent = restore_agent(agent, policy_restore_path, policy_restore_epoch)"
      ],
      "metadata": {
        "id": "BQKlvrbW2nZn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Run evaluation"
      ],
      "metadata": {
        "id": "c4nmGU19C8ZK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate GAS (single episode)\n",
        "frames, infos, steps = demo_evaluate_with_graph(agent, key_graph, env, shadow_renderer, top_cam, ego_cam, front_cam, ENV_NAME, TASK_ID, seed, eval_on_cpu, config['way_steps'], eval_final_goal_threshold,)"
      ],
      "metadata": {
        "id": "Sf_wqNm9FDno"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Visualize results"
      ],
      "metadata": {
        "id": "L3bNDM7YI7GT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize evaluation result\n",
        "print(f\"🌍 Environment: {ENV_NAME}\")\n",
        "print(f\"🎯 Task ID: {TASK_ID}\")\n",
        "if infos[-1][\"success\"] == 1.0:\n",
        "    print(f\"✅ Episode succeeded in {steps} steps\\n\")\n",
        "else:\n",
        "    print(\"❌ Episode failed to reach the final goal\\n\")\n",
        "\n",
        "imageio.mimsave(\"/tmp/demo.mp4\", frames, fps=30)\n",
        "display(Video(\"/tmp/demo.mp4\", embed=True, height=400))"
      ],
      "metadata": {
        "id": "PydDcfcr9Czl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}